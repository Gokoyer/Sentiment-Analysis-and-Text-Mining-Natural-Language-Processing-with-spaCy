{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1f64d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install spaCy and download the English model if not already installed\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example text\n",
    "text = \"spaCy is an amazing NLP library for Python! It can perform tokenization, POS tagging, and named entity recognition.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3814cd8e-1a0d-4392-9dae-ddbb338b5489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tokenization, POS, and Dependency Parsing ===\n",
      "spaCy           POS: NUM        Dep: nsubj\n",
      "is              POS: AUX        Dep: ROOT\n",
      "an              POS: DET        Dep: det\n",
      "amazing         POS: ADJ        Dep: amod\n",
      "NLP             POS: PROPN      Dep: compound\n",
      "library         POS: NOUN       Dep: attr\n",
      "for             POS: ADP        Dep: prep\n",
      "Python          POS: PROPN      Dep: pobj\n",
      "!               POS: PUNCT      Dep: punct\n",
      "It              POS: PRON       Dep: nsubj\n",
      "can             POS: AUX        Dep: aux\n",
      "perform         POS: VERB       Dep: ROOT\n",
      "tokenization    POS: NOUN       Dep: dobj\n",
      ",               POS: PUNCT      Dep: punct\n",
      "POS             POS: PROPN      Dep: compound\n",
      "tagging         POS: NOUN       Dep: conj\n",
      ",               POS: PUNCT      Dep: punct\n",
      "and             POS: CCONJ      Dep: cc\n",
      "named           POS: VERB       Dep: conj\n",
      "entity          POS: NOUN       Dep: compound\n",
      "recognition     POS: NOUN       Dep: oprd\n",
      ".               POS: PUNCT      Dep: punct\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Tokenization with Part-of-speech and Dependency Parsing\n",
    "print(\"=== Tokenization, POS, and Dependency Parsing ===\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:15} POS: {token.pos_:10} Dep: {token.dep_}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544fdc91-d9d9-497e-8a5c-b238221130d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Named Entities ===\n",
      "Entity: NLP                  Label: ORG\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Named Entity Recognition (NER)\n",
    "print(\"=== Named Entities ===\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text:20} Label: {ent.label_}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90314d9-ce4c-41a4-b819-5cb0905f5a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lemmatization ===\n",
      "spaCy           Lemma: spacy\n",
      "is              Lemma: be\n",
      "an              Lemma: an\n",
      "amazing         Lemma: amazing\n",
      "NLP             Lemma: NLP\n",
      "library         Lemma: library\n",
      "for             Lemma: for\n",
      "Python          Lemma: Python\n",
      "!               Lemma: !\n",
      "It              Lemma: it\n",
      "can             Lemma: can\n",
      "perform         Lemma: perform\n",
      "tokenization    Lemma: tokenization\n",
      ",               Lemma: ,\n",
      "POS             Lemma: POS\n",
      "tagging         Lemma: tagging\n",
      ",               Lemma: ,\n",
      "and             Lemma: and\n",
      "named           Lemma: name\n",
      "entity          Lemma: entity\n",
      "recognition     Lemma: recognition\n",
      ".               Lemma: .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Lemmatization\n",
    "print(\"=== Lemmatization ===\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:15} Lemma: {token.lemma_}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2a6000-2e5a-4d1b-b404-00a17ec740f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sentences ===\n",
      "spaCy is an amazing NLP library for Python!\n",
      "It can perform tokenization, POS tagging, and named entity recognition.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Sentence Segmentation\n",
    "print(\"=== Sentences ===\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c8a68cc-67e9-49f4-bd80-017485d545af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stop Word Removal ===\n",
      "Filtered Tokens: ['spaCy', 'amazing', 'NLP', 'library', 'Python', '!', 'perform', 'tokenization', ',', 'POS', 'tagging', ',', 'named', 'entity', 'recognition', '.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Stop Word Removal\n",
    "print(\"=== Stop Word Removal ===\")\n",
    "filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "print(\"Filtered Tokens:\", filtered_tokens)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0921dd2-b7f5-41de-8342-85dd1268c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Parts of Speech (POS) Tagging ===\n",
      "Token           POS        Explanation\n",
      "----------------------------------------\n",
      "spaCy           NUM        numeral\n",
      "is              AUX        auxiliary\n",
      "an              DET        determiner\n",
      "amazing         ADJ        adjective\n",
      "NLP             PROPN      proper noun\n",
      "library         NOUN       noun\n",
      "for             ADP        adposition\n",
      "Python          PROPN      proper noun\n",
      "!               PUNCT      punctuation\n",
      "It              PRON       pronoun\n",
      "can             AUX        auxiliary\n",
      "perform         VERB       verb\n",
      "tokenization    NOUN       noun\n",
      ",               PUNCT      punctuation\n",
      "POS             PROPN      proper noun\n",
      "tagging         NOUN       noun\n",
      ",               PUNCT      punctuation\n",
      "and             CCONJ      coordinating conjunction\n",
      "named           VERB       verb\n",
      "entity          NOUN       noun\n",
      "recognition     NOUN       noun\n",
      ".               PUNCT      punctuation\n"
     ]
    }
   ],
   "source": [
    "# 6. Parts of Speech Tagging with Explanation\n",
    "print(\"=== Parts of Speech (POS) Tagging ===\")\n",
    "print(f\"{'Token':15} {'POS':10} Explanation\")\n",
    "print(\"-\" * 40)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:15} {token.pos_:10} {spacy.explain(token.pos_)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
